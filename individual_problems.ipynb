{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Problems\n",
    "\n",
    "Split \"Category\" and \"Misconception\" into 3 separate classification problems.\n",
    "\n",
    "1. Classification on whether the answer was correctly answered\n",
    "2. Classification on whether the right \"reason\" was provided\n",
    "3. Classification on the misconception type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 25/08/2025   | Martin | Created   | Created notebook for data processing | \n",
    "| 26/08/2025   | Martin | New   | Completed classification model using universal sentence encoder for question correct | \n",
    "| 16/09/2025   | Martin | New   | Completed end-to-end model: cascading results | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Universal Sentence Encoder](#universal-sentence-encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "SEED = 43\n",
    "PROJ_NAME = \"math_misunderstandings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminimartzz\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(\"data/raw/train.csv\")\n",
    "test = pl.read_csv(\"data/raw/test.csv\")\n",
    "sample_submission = pl.read_csv(\"data/raw/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Category</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;True_Neither&quot;</td></tr><tr><td>&quot;True_Misconception&quot;</td></tr><tr><td>&quot;False_Neither&quot;</td></tr><tr><td>&quot;True_Correct&quot;</td></tr><tr><td>&quot;False_Misconception&quot;</td></tr><tr><td>&quot;False_Correct&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6,)\n",
       "Series: 'Category' [str]\n",
       "[\n",
       "\t\"True_Neither\"\n",
       "\t\"True_Misconception\"\n",
       "\t\"False_Neither\"\n",
       "\t\"True_Correct\"\n",
       "\t\"False_Misconception\"\n",
       "\t\"False_Correct\"\n",
       "]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation_1(pldf: pl.DataFrame, encoder=None) -> pl.DataFrame:\n",
    "  \"\"\"\n",
    "  Correct:\n",
    "    - \"True\": 1\n",
    "    - \"False\": 0\n",
    "  Error:\n",
    "    - \"Correct\": 2\n",
    "    - \"Neither\": 0\n",
    "    - \"Misconception\": 1\n",
    "  Misconception:\n",
    "    - Label_encoder\n",
    "  \"\"\"\n",
    "  pldf = pldf.with_columns(\n",
    "    pl.col('Category').str.split_exact(\"_\", 1)\n",
    "    .struct.rename_fields([ \"Correct\", \"Error\" ])\n",
    "    .alias(\"fields\")\n",
    "  ).unnest(\"fields\")\n",
    "\n",
    "  # Remap according to above encoding\n",
    "  if encoder is None:\n",
    "    enc = LabelEncoder()\n",
    "    pldf = pldf.with_columns(\n",
    "      Correct=pl.col(\"Correct\").replace_strict([\"True\", \"False\"], [1, 0], return_dtype=pl.Int8),\n",
    "      Error=pl.col(\"Error\").replace_strict([\"Correct\", \"Neither\", \"Misconception\"], [2, 0, 1], return_dtype=pl.Int8),\n",
    "      Misconception=pl.col(\"Misconception\").map_batches(enc.fit_transform)\n",
    "    )\n",
    "    return pldf, enc\n",
    "  else:\n",
    "    pldf = pldf.with_columns(\n",
    "      Correct=pl.col(\"Correct\").replace_strict([\"True\", \"False\"], [1, 0], return_dtype=pl.Int8),\n",
    "      Error=pl.col(\"Error\").replace_strict([\"Correct\", \"Neither\", \"Misconception\"], [2, 0, 1], return_dtype=pl.Int8),\n",
    "      Misconception=pl.col(\"Misconception\").map_batches(enc.transform)\n",
    "    )\n",
    "    return pldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans, enc = data_transformation_1(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>QuestionId</th><th>QuestionText</th><th>MC_Answer</th><th>StudentExplanation</th><th>Category</th><th>Misconception</th><th>Correct</th><th>Error</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>0</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;0ne third is equal to tree nin…</td><td>&quot;True_Correct&quot;</td><td>21</td><td>1</td><td>2</td></tr><tr><td>1</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 / 3 because 6 over 9 is 2 th…</td><td>&quot;True_Correct&quot;</td><td>21</td><td>1</td><td>2</td></tr><tr><td>2</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 3rd is half of 3 6th, so it …</td><td>&quot;True_Neither&quot;</td><td>21</td><td>1</td><td>0</td></tr><tr><td>3</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 goes into everything and 3 g…</td><td>&quot;True_Neither&quot;</td><td>21</td><td>1</td><td>0</td></tr><tr><td>4</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 out of every 3 isn&#x27;t coloure…</td><td>&quot;True_Correct&quot;</td><td>21</td><td>1</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌────────┬────────────┬─────────────┬─────────────┬───┬─────────────┬────────────┬─────────┬───────┐\n",
       "│ row_id ┆ QuestionId ┆ QuestionTex ┆ MC_Answer   ┆ … ┆ Category    ┆ Misconcept ┆ Correct ┆ Error │\n",
       "│ ---    ┆ ---        ┆ t           ┆ ---         ┆   ┆ ---         ┆ ion        ┆ ---     ┆ ---   │\n",
       "│ i64    ┆ i64        ┆ ---         ┆ str         ┆   ┆ str         ┆ ---        ┆ i8      ┆ i8    │\n",
       "│        ┆            ┆ str         ┆             ┆   ┆             ┆ i64        ┆         ┆       │\n",
       "╞════════╪════════════╪═════════════╪═════════════╪═══╪═════════════╪════════════╪═════════╪═══════╡\n",
       "│ 0      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ True_Correc ┆ 21         ┆ 1       ┆ 2     │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆ t           ┆            ┆         ┆       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆             ┆            ┆         ┆       │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆             ┆            ┆         ┆       │\n",
       "│ 1      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ True_Correc ┆ 21         ┆ 1       ┆ 2     │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆ t           ┆            ┆         ┆       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆             ┆            ┆         ┆       │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆             ┆            ┆         ┆       │\n",
       "│ 2      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ True_Neithe ┆ 21         ┆ 1       ┆ 0     │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆ r           ┆            ┆         ┆       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆             ┆            ┆         ┆       │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆             ┆            ┆         ┆       │\n",
       "│ 3      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ True_Neithe ┆ 21         ┆ 1       ┆ 0     │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆ r           ┆            ┆         ┆       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆             ┆            ┆         ┆       │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆             ┆            ┆         ┆       │\n",
       "│ 4      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ True_Correc ┆ 21         ┆ 1       ┆ 2     │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆ t           ┆            ┆         ┆       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆             ┆            ┆         ┆       │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆             ┆            ┆         ┆       │\n",
       "└────────┴────────────┴─────────────┴─────────────┴───┴─────────────┴────────────┴─────────┴───────┘"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Sentence Encoder\n",
    "\n",
    "Using Google's Universal Sentence encoder and a basic transformer architecture. \n",
    "\n",
    "[Link](https://www.kaggle.com/models/google/universal-sentence-encoder)\n",
    "\n",
    "- Each set of text will have it's own encoding\n",
    "- \"Correct\": `QuestionText` + `MC_Answer`\n",
    "- \"Error\": `QuestionText` + `StudentExplanation`\n",
    "- \"Misconception\":`QuestionText` + `MC_Answer` +  `StudentExplanation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Software\\venv\\py311_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras as keras\n",
    "from wandb.integration.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>QuestionId</th><th>QuestionText</th><th>MC_Answer</th><th>StudentExplanation</th><th>Category</th><th>Misconception</th><th>Correct</th><th>Error</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>0</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;0ne third is equal to tree nin…</td><td>&quot;True_Correct&quot;</td><td>21</td><td>1</td><td>2</td></tr><tr><td>1</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 / 3 because 6 over 9 is 2 th…</td><td>&quot;True_Correct&quot;</td><td>21</td><td>1</td><td>2</td></tr><tr><td>2</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 3rd is half of 3 6th, so it …</td><td>&quot;True_Neither&quot;</td><td>21</td><td>1</td><td>0</td></tr><tr><td>3</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 goes into everything and 3 g…</td><td>&quot;True_Neither&quot;</td><td>21</td><td>1</td><td>0</td></tr><tr><td>4</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 out of every 3 isn&#x27;t coloure…</td><td>&quot;True_Correct&quot;</td><td>21</td><td>1</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌────────┬────────────┬─────────────┬─────────────┬───┬─────────────┬────────────┬─────────┬───────┐\n",
       "│ row_id ┆ QuestionId ┆ QuestionTex ┆ MC_Answer   ┆ … ┆ Category    ┆ Misconcept ┆ Correct ┆ Error │\n",
       "│ ---    ┆ ---        ┆ t           ┆ ---         ┆   ┆ ---         ┆ ion        ┆ ---     ┆ ---   │\n",
       "│ i64    ┆ i64        ┆ ---         ┆ str         ┆   ┆ str         ┆ ---        ┆ i8      ┆ i8    │\n",
       "│        ┆            ┆ str         ┆             ┆   ┆             ┆ i64        ┆         ┆       │\n",
       "╞════════╪════════════╪═════════════╪═════════════╪═══╪═════════════╪════════════╪═════════╪═══════╡\n",
       "│ 0      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ True_Correc ┆ 21         ┆ 1       ┆ 2     │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆ t           ┆            ┆         ┆       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆             ┆            ┆         ┆       │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆             ┆            ┆         ┆       │\n",
       "│ 1      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ True_Correc ┆ 21         ┆ 1       ┆ 2     │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆ t           ┆            ┆         ┆       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆             ┆            ┆         ┆       │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆             ┆            ┆         ┆       │\n",
       "│ 2      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ True_Neithe ┆ 21         ┆ 1       ┆ 0     │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆ r           ┆            ┆         ┆       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆             ┆            ┆         ┆       │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆             ┆            ┆         ┆       │\n",
       "│ 3      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ True_Neithe ┆ 21         ┆ 1       ┆ 0     │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆ r           ┆            ┆         ┆       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆             ┆            ┆         ┆       │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆             ┆            ┆         ┆       │\n",
       "│ 4      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ True_Correc ┆ 21         ┆ 1       ┆ 2     │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆ t           ┆            ┆         ┆       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆             ┆            ┆         ┆       │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆             ┆            ┆         ┆       │\n",
       "└────────┴────────────┴─────────────┴─────────────┴───┴─────────────┴────────────┴─────────┴───────┘"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the universal sentence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Sample Embeddings ==========\n",
      "Original Question: It takes \\( 3 \\) people a total of \\( 192 \\) hours to build a wall.\n",
      "\n",
      "How long would it take if \\( 12 \\) people built the same wall?\n",
      "\n",
      "Output Embeddings\n",
      "tf.Tensor(\n",
      "[-6.68102205e-02 -6.10626899e-02  1.79229137e-02  4.19839323e-02\n",
      " -1.17873782e-02  5.08639403e-02  5.86139075e-02 -7.71604329e-02\n",
      "  1.32026728e-02 -6.27243444e-02  6.84483647e-02 -3.29053663e-02\n",
      "  4.53919359e-02  7.36617520e-02  1.81412511e-02 -1.50903361e-02\n",
      "  2.54544187e-02  6.20670244e-02 -3.70359793e-02  2.04275288e-02\n",
      " -6.18070327e-02 -3.01178973e-02 -5.99907758e-03 -1.10479947e-02\n",
      " -2.91003920e-02 -1.42776025e-02 -4.32836525e-02 -3.94087518e-03\n",
      " -3.53350816e-03 -7.30098933e-02 -4.24190052e-02  2.64390949e-02\n",
      " -5.52046113e-02  2.33912617e-02  6.94109201e-02  5.10292538e-02\n",
      "  2.52680648e-02 -6.61791861e-02  3.16250436e-02 -1.98846310e-02\n",
      " -3.99743393e-02  8.72335285e-02 -4.19758111e-02  7.72131979e-02\n",
      " -7.08319619e-02  2.61147581e-02 -4.04614806e-02 -4.93845455e-02\n",
      " -3.31763811e-02 -1.60955917e-02 -1.07236076e-02  5.98919317e-02\n",
      "  3.80541990e-03 -5.66648357e-02 -7.69792823e-03 -1.17393918e-02\n",
      " -7.49694183e-02  2.14861110e-02 -5.14598079e-02  4.34692241e-02\n",
      "  2.40898822e-02  1.49512645e-02 -6.11525699e-02 -7.77672976e-02\n",
      " -1.34805376e-02 -6.95569962e-02 -3.31314728e-02  3.49054784e-02\n",
      " -1.71698406e-02 -1.04060452e-02 -2.26935442e-03 -8.34302083e-02\n",
      "  3.07741202e-02  8.29793978e-03 -5.99741228e-02 -7.77476281e-03\n",
      " -1.72180664e-02  4.64875922e-02  7.95460418e-02  8.34427699e-02\n",
      "  2.45535187e-02  4.10960987e-02 -7.99492095e-03 -5.80983236e-02\n",
      "  2.14255303e-02  6.49054572e-02 -8.60294998e-02 -1.75800044e-02\n",
      " -2.26796735e-02 -3.06178052e-02  5.87399192e-02 -5.97829558e-02\n",
      "  3.74559797e-02  6.67300597e-02  1.15184877e-02 -3.87943573e-02\n",
      "  2.37876736e-02 -6.47067055e-02 -9.59288795e-03 -7.89399743e-02\n",
      "  1.08215958e-03  3.76099125e-02 -1.99182536e-02 -2.01245751e-02\n",
      " -4.21564057e-02  4.40743938e-02 -1.69528443e-02  3.16576287e-02\n",
      " -4.68964651e-02  1.19881285e-02  2.90099476e-02  1.84858497e-02\n",
      "  5.38878813e-02 -1.47480508e-02 -4.20522839e-02 -5.81045402e-03\n",
      " -3.06742061e-02  3.13633904e-02 -1.21422410e-02  5.32317646e-02\n",
      "  2.08583567e-02  7.04816431e-02  4.01364304e-02  1.98662467e-02\n",
      "  8.85807909e-03  1.31029198e-02  5.54475524e-02  3.95068601e-02\n",
      " -5.78372777e-02  2.88315006e-02 -4.63113263e-02  5.51945046e-02\n",
      " -4.16433066e-02 -6.36804402e-02 -4.40179519e-02 -5.23314849e-02\n",
      " -8.34160149e-02  3.80996289e-03  3.71497986e-03  4.52706367e-02\n",
      " -3.30513790e-02  3.78392227e-02  3.95187140e-02  1.94133278e-02\n",
      "  2.03421284e-02  3.17246355e-02  5.00346571e-02  6.99572563e-02\n",
      " -2.48199962e-02 -3.81369255e-02 -5.00927726e-03  8.53298753e-02\n",
      "  3.62452567e-02 -5.79552026e-03  5.53880669e-02 -4.94101159e-02\n",
      "  5.36875501e-02  8.55076686e-02 -3.66758816e-02 -1.02641406e-02\n",
      " -5.79232611e-02  5.51067740e-02  6.64272830e-02  7.78119117e-02\n",
      " -7.70241255e-04 -1.50503442e-02  5.78931086e-02 -3.13115232e-02\n",
      " -6.91593206e-03  4.37553190e-02 -5.48147671e-02  6.98836669e-02\n",
      " -7.78008625e-02  1.82909723e-02 -8.04050267e-02  3.15463357e-02\n",
      "  2.10879836e-02  2.80462503e-02 -1.72940944e-03 -1.77237019e-02\n",
      " -6.48785606e-02  5.45686409e-02  8.49933699e-02  2.07718345e-03\n",
      "  3.87309236e-03  6.74944520e-02 -2.11278368e-02  5.04723452e-02\n",
      " -9.32813529e-03  1.86524875e-02  7.71353021e-03  6.15512440e-03\n",
      " -5.13075925e-02  6.93999529e-02 -3.56082693e-02 -1.42571365e-03\n",
      " -4.47267108e-02 -4.34046909e-02 -3.57397534e-02 -5.21842018e-02\n",
      "  2.16704346e-02  3.67390066e-02 -2.14723721e-02 -2.87844818e-02\n",
      "  4.14869487e-02  4.11023162e-02  8.14981875e-04 -5.09521700e-02\n",
      " -1.26421181e-02  3.07582840e-02  4.25820015e-02  6.28792271e-02\n",
      " -2.16747317e-02  5.74610233e-02  5.13551645e-02 -2.45137978e-03\n",
      " -2.56636310e-02  1.91903561e-02 -6.15669936e-02 -4.04975191e-02\n",
      "  2.10958556e-03 -4.06312235e-02  6.68786615e-02 -4.62952740e-02\n",
      " -2.98415013e-02 -6.02765791e-02 -1.22133056e-02 -1.80861596e-02\n",
      "  3.31428163e-02 -3.11755519e-02 -2.94174831e-02 -6.02024496e-02\n",
      " -9.95412003e-03 -9.17953700e-02  1.57769211e-02 -2.44368799e-02\n",
      "  8.03401694e-02 -4.29546796e-02 -9.71948728e-03  2.67642420e-02\n",
      "  4.14687134e-02  7.23666921e-02 -1.52020501e-02 -7.80671164e-02\n",
      "  9.05986468e-04  7.36553073e-02  3.76339140e-03  3.90263610e-02\n",
      "  7.47214034e-02  7.44417235e-02 -4.39325944e-02 -2.53679585e-02\n",
      "  4.56969775e-02  3.14974450e-02  3.53096686e-02  2.99302731e-02\n",
      "  8.36602077e-02  4.87718992e-02  6.14699908e-03 -3.43133770e-02\n",
      " -2.83364602e-03  3.95745002e-02 -7.67686963e-02  1.28619028e-02\n",
      " -6.57914728e-02 -4.26956601e-02  2.15817466e-02 -3.34144123e-02\n",
      "  4.98208143e-02  5.15628755e-02  5.86656593e-02 -1.81181692e-02\n",
      " -1.66014675e-02 -2.79545579e-02 -7.63254464e-02  2.85149161e-02\n",
      "  5.59721626e-02  5.56975938e-02 -6.71681436e-03  5.79221845e-02\n",
      " -2.73696259e-02 -6.26664013e-02 -2.62082983e-02 -7.71814259e-03\n",
      "  3.38883922e-02 -3.72409672e-02  1.95212755e-02  3.06958426e-02\n",
      " -1.82487760e-02 -3.66459303e-02  3.11488751e-02 -2.84845550e-02\n",
      " -2.61683799e-02  3.22910771e-02  4.82244454e-02 -3.17720547e-02\n",
      "  5.60759045e-02  5.09626837e-03 -1.51150664e-02 -3.32152210e-02\n",
      "  1.45645384e-02 -4.00886312e-02  8.54810048e-03  3.27418819e-02\n",
      " -5.76222166e-02 -5.11993319e-02  5.62894009e-02  4.04517539e-02\n",
      "  2.55672261e-02  2.50147972e-02  4.33133431e-02 -3.29236612e-02\n",
      "  5.80925308e-02 -7.66437426e-02 -5.43265641e-02  6.01116903e-02\n",
      " -2.72151046e-02  1.94637738e-02  8.78205672e-02  5.65651990e-02\n",
      " -2.98292730e-02  3.87054831e-02 -4.82444316e-02  1.59505680e-02\n",
      " -8.52629319e-02 -1.28252087e-02 -2.70918179e-02  4.96850275e-02\n",
      " -9.32114348e-02 -1.33820679e-02  5.19788638e-02 -2.39336601e-04\n",
      " -3.90435383e-02  4.52292152e-02 -2.60537714e-02 -2.32734747e-05\n",
      " -2.05589477e-02 -1.56496726e-02 -3.97970341e-02  3.43459249e-02\n",
      "  6.13740869e-02  3.16618681e-02 -1.28001291e-02  1.23858526e-02\n",
      " -8.95337388e-02  5.50575294e-02 -5.69811789e-03 -7.48070553e-02\n",
      " -3.00210416e-02 -2.07060836e-02 -1.23271849e-02 -2.87481975e-02\n",
      " -1.10089611e-02 -2.31434181e-02 -1.95013676e-02  2.08935998e-02\n",
      " -8.74005258e-02  3.21161817e-03  1.19040124e-02 -2.02523172e-02\n",
      " -8.19115639e-02 -2.26438623e-02 -2.01687831e-02  2.08784025e-02\n",
      " -4.16695625e-02  1.16467178e-02  6.74844394e-03  6.80025965e-02\n",
      "  1.00831864e-02 -5.66450804e-02 -2.89195236e-02  2.63908394e-02\n",
      "  5.96488342e-02  2.86503080e-02  6.05725311e-02 -7.16104498e-03\n",
      "  1.77938901e-02 -2.72465385e-02 -4.10614200e-02  9.21896845e-03\n",
      "  2.03575809e-02 -8.42359569e-03  2.90097110e-02  5.77431843e-02\n",
      " -6.93265814e-03  5.36620035e-04 -4.82788868e-02 -4.90003452e-02\n",
      " -7.10979030e-02 -4.83451486e-02 -7.37312809e-02  3.56186032e-02\n",
      " -1.22029735e-02  2.52356008e-02 -2.39319950e-02 -5.14576398e-02\n",
      " -4.44542170e-02 -8.04668665e-03  3.08579206e-02 -3.33982594e-02\n",
      "  3.32268961e-02 -1.92623865e-02 -3.15509811e-02 -2.34953258e-02\n",
      "  7.18034280e-04  1.18145514e-02 -6.61920682e-02 -1.31665301e-02\n",
      " -2.74594836e-02 -8.90699700e-02 -1.57933822e-03 -8.65829811e-02\n",
      "  1.97035000e-02  5.66369742e-02 -6.08234433e-03 -1.79050006e-02\n",
      " -8.66252258e-02 -7.42094219e-02  4.05576378e-02 -2.24938281e-02\n",
      "  1.97506901e-02  2.09074356e-02 -2.58144923e-02  1.44472038e-02\n",
      " -3.27406563e-02  4.45362814e-02  8.32866784e-03  6.51909411e-02\n",
      "  1.30407829e-02  3.57112065e-02 -5.38996346e-02  3.39829139e-02\n",
      " -6.49615675e-02  9.37188789e-02 -2.07889266e-02 -3.96386161e-02\n",
      "  5.20481840e-02  5.27120084e-02 -2.35886686e-02 -5.22916578e-02\n",
      " -4.53079641e-02  1.02996372e-03 -3.68649513e-03  1.26827797e-02\n",
      " -7.31200501e-02  6.35810420e-02 -3.44970748e-02  2.00762823e-02\n",
      " -2.20770203e-02  1.25368377e-02 -3.57569195e-02  2.54425686e-02\n",
      " -4.18395065e-02 -3.38607840e-02 -2.36382391e-02  6.44725710e-02\n",
      " -3.68210077e-02 -9.83909052e-03  6.66447133e-02 -3.06694955e-02\n",
      "  1.89046822e-02 -2.41795313e-02  5.91280796e-02  1.45492638e-02\n",
      " -1.78724751e-02  7.12346882e-02 -3.76290008e-02 -6.72054419e-04\n",
      "  6.00252412e-02  6.46760315e-02  2.92172730e-02  3.00357193e-02\n",
      " -5.82562983e-02 -9.57778189e-03  2.63169762e-02  4.55999933e-02\n",
      "  5.46870492e-02 -2.25925352e-02  7.38202259e-02 -4.48636487e-02\n",
      " -8.25247988e-02 -5.50100990e-02 -6.23307005e-02  2.72539370e-02\n",
      "  1.68785814e-03  5.32905273e-02 -3.73859704e-02 -7.86403790e-02\n",
      " -1.18921875e-04 -1.48632498e-02  9.41782668e-02 -2.90633179e-02\n",
      " -4.72582169e-02 -3.55070494e-02  6.87444583e-02  4.56740260e-02\n",
      "  3.56897935e-02 -5.94753325e-02 -7.49877840e-02  6.42378479e-02\n",
      "  1.84823703e-02  2.73627695e-02 -5.22026569e-02  4.63449769e-02\n",
      " -5.37061132e-02  6.41188547e-02 -2.50099357e-02  6.83370084e-02\n",
      " -5.75221851e-02 -4.22854871e-02  1.66918180e-04 -6.91052899e-02], shape=(512,), dtype=float32)\n",
      "Original Question: Which number is the greatest?\n",
      "\n",
      "Output Embeddings\n",
      "tf.Tensor(\n",
      "[-0.08858593 -0.10454097 -0.03029074  0.06955765 -0.01401862  0.00756847\n",
      " -0.00110715 -0.02343804  0.04359515  0.01318863 -0.06084866  0.03784883\n",
      "  0.00243293 -0.02175304  0.05152017 -0.01364989 -0.03053451 -0.04108219\n",
      " -0.01992057 -0.00778103  0.08318446 -0.01464759  0.05132075  0.03961849\n",
      " -0.05137337  0.05389096 -0.04484871 -0.04930652 -0.01879343 -0.00886439\n",
      "  0.00931153 -0.0144882   0.01870311 -0.05839058 -0.03833834  0.01397586\n",
      " -0.04737962  0.06732118 -0.02101965  0.02730195 -0.03283715 -0.0659802\n",
      "  0.03845539  0.10084056  0.00897017 -0.01416191 -0.06144271  0.0533947\n",
      "  0.04432887  0.01845738  0.01096095  0.1071464  -0.08026408 -0.0895896\n",
      "  0.02154766  0.03348036 -0.0848955  -0.02096984 -0.09502111 -0.00782192\n",
      " -0.03348289  0.01027226  0.0389042  -0.06737886 -0.02919276 -0.01472221\n",
      " -0.02318908  0.01692313  0.04426005 -0.00050091  0.01092678  0.04767376\n",
      " -0.06996557  0.10641519  0.04453488  0.01045599  0.01857488 -0.0681095\n",
      "  0.02207772  0.03277212  0.02633967  0.00330025 -0.0040439   0.01614347\n",
      " -0.03444764 -0.06897312 -0.06108713  0.04617738 -0.03347922  0.03371289\n",
      "  0.00772252 -0.02787326 -0.10056188  0.04396658 -0.06126487 -0.04675703\n",
      "  0.07248851  0.07988999  0.00303068 -0.01652364 -0.02321212  0.09138595\n",
      "  0.10093603 -0.03786527  0.00169359  0.04205697  0.02825548  0.03935948\n",
      " -0.05021798  0.05622718 -0.06279452  0.05205585 -0.09899719  0.0088999\n",
      "  0.03467391 -0.03395723  0.03355071  0.0123512   0.0040086  -0.00407115\n",
      "  0.03261118 -0.01612204 -0.01342622  0.00383943 -0.06633101 -0.0308682\n",
      " -0.01088333 -0.03156069  0.03212658 -0.0057318   0.03604997 -0.0336263\n",
      "  0.04492907 -0.00683228 -0.03411175  0.01787843 -0.0087938  -0.02907164\n",
      " -0.06059416  0.03289697  0.0005455  -0.0826532   0.03280239 -0.00526732\n",
      " -0.00136512  0.00630079  0.0160232  -0.0403345  -0.01274003 -0.02368844\n",
      " -0.02606368  0.10075246 -0.04374238  0.02952743 -0.03849527 -0.05830271\n",
      " -0.02551588  0.08616383 -0.01024737  0.05146173  0.00565109 -0.06099654\n",
      "  0.05241543  0.07022616 -0.02378736  0.03122754 -0.02455449 -0.05900494\n",
      " -0.03206268  0.02433052  0.0044303   0.07609539  0.07759124  0.0459853\n",
      " -0.02473224  0.02452053  0.0190687   0.00963494 -0.01065421  0.01200317\n",
      "  0.00565595 -0.02482704  0.10520865 -0.03217313 -0.004575    0.02054786\n",
      "  0.00898593  0.04433088  0.03208943  0.06934375 -0.0258919   0.06244501\n",
      "  0.03994952  0.01759302  0.0131157   0.07582037  0.00201183 -0.06272862\n",
      "  0.02048882 -0.05199162 -0.00569365 -0.05519346 -0.03000804 -0.03402394\n",
      " -0.01844454 -0.05470306 -0.06927296 -0.01242549  0.00869225  0.03383235\n",
      "  0.00199858 -0.03826773  0.04086416  0.00635226  0.07677663 -0.00370129\n",
      " -0.01924882  0.0955879   0.02072507  0.00565661 -0.01870048 -0.00320489\n",
      "  0.04567994  0.02767418  0.01014343  0.02710551  0.00576134  0.06479826\n",
      "  0.06316641 -0.04544054 -0.01887552 -0.06280124  0.03250045  0.07647977\n",
      "  0.00665452 -0.0452686   0.0877915  -0.05958527 -0.00786369  0.06660476\n",
      " -0.07922363  0.03040761 -0.00343335 -0.02873489  0.04571326  0.09620686\n",
      "  0.0157069   0.06076637  0.10744824  0.02641681  0.02059975 -0.02585454\n",
      "  0.01213172  0.01351726  0.03311531 -0.02528706  0.04055396 -0.05606116\n",
      " -0.02578151  0.03116697  0.03367505 -0.01569231  0.10667868  0.02383798\n",
      " -0.0395936   0.02289312 -0.03643836  0.07706581 -0.00365929 -0.00278816\n",
      " -0.02427511  0.05790412 -0.05611298 -0.07514229  0.02205911 -0.04395522\n",
      " -0.00691128  0.03102194 -0.02706874  0.06224118 -0.01039813 -0.00215046\n",
      " -0.06077059 -0.02549811  0.00166113  0.0367051  -0.03175722  0.01313432\n",
      " -0.00884288  0.01919536 -0.01294663  0.087246   -0.07386694 -0.02467988\n",
      "  0.06048371  0.06358805 -0.03416799  0.02178619  0.01461565 -0.01324651\n",
      " -0.01645085 -0.0366655  -0.0978906  -0.04544207 -0.00018618  0.05768435\n",
      " -0.00121638 -0.00387999  0.08142299 -0.01323917 -0.02237075 -0.02744295\n",
      " -0.08871967  0.04230377 -0.01013084  0.03250377 -0.03215897 -0.02640622\n",
      " -0.01637044  0.00769232 -0.01686384  0.02330896 -0.01591409  0.04813397\n",
      "  0.05824497  0.01165114  0.02063214  0.0256714  -0.10707743  0.05038261\n",
      "  0.06445018  0.00656557  0.04153629 -0.08765498 -0.0095477  -0.00558889\n",
      " -0.02327965  0.01624384  0.0113255  -0.02559115  0.05247113 -0.02231142\n",
      " -0.04578321  0.08338229 -0.04897216  0.02205825  0.02904398  0.00422814\n",
      "  0.00500601  0.0126513  -0.00599648  0.03093063 -0.00966384 -0.04884569\n",
      "  0.00790912  0.00257872 -0.09981675 -0.00133204  0.05290824  0.0155968\n",
      " -0.05862259 -0.00743761  0.06155781 -0.04622898 -0.04338247  0.00662729\n",
      " -0.09073531  0.04497681  0.01076091 -0.03439585  0.05608307  0.03682675\n",
      " -0.04787954  0.06506564  0.02114219  0.01272717 -0.00832721 -0.04353716\n",
      " -0.00134722  0.00142293 -0.01149403 -0.01806167  0.03128331  0.04709768\n",
      " -0.01826768  0.06130455 -0.01225228 -0.04016187  0.04796262  0.01110363\n",
      "  0.04189596  0.00398387 -0.04843871  0.01096557  0.05525271 -0.01137622\n",
      " -0.04549262 -0.07217874 -0.04712436 -0.00546204  0.02598433 -0.03096276\n",
      "  0.0430581  -0.00724039 -0.03701441  0.04809744  0.05783966 -0.04676673\n",
      " -0.00837265 -0.03420131  0.07042294  0.01797238  0.01068558  0.02621324\n",
      "  0.05822323 -0.03217265 -0.04550537  0.09734438  0.02811233  0.0179552\n",
      "  0.01785401 -0.00190625  0.01629846 -0.04028367  0.04435045  0.05818169\n",
      " -0.02332133  0.09118392 -0.03090198 -0.01958592  0.03479099  0.02488049\n",
      " -0.05783123 -0.0229858  -0.0137186   0.04280875 -0.09173305  0.05161125\n",
      " -0.00585268 -0.0432939   0.0108758  -0.01934962  0.0192776   0.04583104\n",
      "  0.03871275 -0.04964426  0.04021686 -0.02707166 -0.00709346  0.03546579\n",
      " -0.02035898 -0.0324821  -0.01560521  0.02448747 -0.02259604 -0.06985957\n",
      "  0.06278983  0.04985302 -0.00543755 -0.00395672  0.00474045 -0.0492328\n",
      " -0.00754666 -0.06337797  0.02010901 -0.08423154  0.03601729  0.00613727\n",
      " -0.03608109  0.05003919  0.04407221 -0.02199455 -0.00687989  0.06580251\n",
      "  0.05987145 -0.06240621  0.00403488 -0.03056759  0.10668141  0.03398861\n",
      "  0.08236738 -0.08867222  0.01857461  0.01825115 -0.02017401  0.01111284\n",
      " -0.09632117  0.034836    0.00644817 -0.03885502  0.01935644 -0.03750133\n",
      " -0.04426736 -0.08585469  0.06046684  0.01251691 -0.02068916 -0.01885199\n",
      "  0.08641723  0.00185945  0.04115343  0.01570375 -0.00537224  0.09414186\n",
      "  0.04618091  0.01549132 -0.01868907 -0.02870218 -0.0024311  -0.03995491\n",
      "  0.01759241  0.00878035], shape=(512,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "embed = hub.load(\"models/universal_sentence_encoder_v2\")\n",
    "\n",
    "# Create samples for visualisation\n",
    "sample = train_trans.sample(2, seed=SEED)\n",
    "qns_sample = sample['QuestionText']\n",
    "qns_embed = embed(qns_sample)\n",
    "\n",
    "print(\"========= Sample Embeddings ==========\")\n",
    "for samp, emb in zip(qns_sample, qns_embed):\n",
    "  print(f\"Original Question: {samp}\")\n",
    "  print(\"\")\n",
    "  print(f\"Output Embeddings\")\n",
    "  print(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = train_trans['Category']\n",
    "train_split, val_split = train_test_split(train_trans, train_size=0.7, random_state=SEED, stratify=category)\n",
    "\n",
    "train_correct = train_split.select('QuestionText', 'MC_Answer', 'Correct')\n",
    "train_error = train_split.select('QuestionText', 'StudentExplanation', 'Error')\n",
    "train_misconception = train_split.select('QuestionText', 'MC_Answer', 'StudentExplanation', 'Misconception')\n",
    "\n",
    "val_correct = val_split.select('QuestionText', 'MC_Answer', 'Correct')\n",
    "val_error = val_split.select('QuestionText', 'StudentExplanation', 'Error')\n",
    "val_misconception = val_split.select('QuestionText', 'MC_Answer', 'StudentExplanation', 'Misconception')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFN for Correct Answer Classification\n",
    "\n",
    "- 0: Wrong Answer\n",
    "- 1: Correct Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandb configurations\n",
    "config = {\n",
    "  \"embed_dim\": 512,\n",
    "  \"ffn_dim\": 256,\n",
    "  \"dropout_rate\": 0.1,\n",
    "  \"num_classes\": 1,\n",
    "  \"optimizer\": \"adam\",\n",
    "  \"loss\": \"binary_crossentropy\",\n",
    "}\n",
    "\n",
    "run = wandb.init(\n",
    "  project=PROJ_NAME,\n",
    "  notes=\"Split tasks into separate classification tasks\",\n",
    "  tags=[\"baseline\", \"separate_tasks\", \"univ_sent\", \"correct\"],\n",
    "  config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_18      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ input_layer_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ input_layer_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_50          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_52          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dropout_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dropout_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_51          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_53          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dropout_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dropout_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_54          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,260</span> │ dropout_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_55          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │ dropout_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_18      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ input_layer_17[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ input_layer_18[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_50          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_52          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dropout_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dropout_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_51          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_53          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dropout_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dropout_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_54          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │     \u001b[38;5;34m10,260\u001b[0m │ dropout_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_55          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m21\u001b[0m │ dropout_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">804,393</span> (3.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m804,393\u001b[0m (3.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">801,321</span> (3.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m801,321\u001b[0m (3.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> (12.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,072\u001b[0m (12.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qns_input = keras.layers.Input(shape=(config['embed_dim'], )) # Questions\n",
    "ans_input = keras.layers.Input(shape=(config['embed_dim'], )) # Answers\n",
    "\n",
    "# Questions model\n",
    "x1 = keras.layers.Dense(config['embed_dim'], activation=\"relu\")(qns_input)\n",
    "x1 = keras.layers.Dropout(config['dropout_rate'])(x1)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "x1 = keras.layers.Dense(config['ffn_dim'], activation=\"relu\")(x1)\n",
    "x1 = keras.layers.Dropout(config['dropout_rate'])(x1)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "# Answers model\n",
    "x2 = keras.layers.Dense(config['embed_dim'], activation=\"relu\")(ans_input)\n",
    "x2 = keras.layers.Dropout(config['dropout_rate'])(x2)\n",
    "x2 = keras.layers.BatchNormalization()(x2)\n",
    "x2 = keras.layers.Dense(config['ffn_dim'], activation=\"relu\")(x2)\n",
    "x2 = keras.layers.Dropout(config['dropout_rate'])(x2)\n",
    "x2 = keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "# Combined model\n",
    "x3 = keras.layers.concatenate([x1, x2])\n",
    "x3 = keras.layers.Dropout(config['dropout_rate'])(x3)\n",
    "x3 = keras.layers.Dense(20, activation=\"relu\")(x3)\n",
    "x3 = keras.layers.Dropout(config['dropout_rate'])(x3)\n",
    "outputs = keras.layers.Dense(config['num_classes'], activation=\"sigmoid\")(x3)\n",
    "\n",
    "model_correct = keras.Model(inputs=[qns_input, ans_input], outputs=outputs)\n",
    "\n",
    "model_correct.compile(\n",
    "  optimizer=config['optimizer'],\n",
    "  loss=config['loss'],\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "model_correct.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qns_embed = embed(train_correct['QuestionText'])\n",
    "train_ans_embed = embed(train_correct['MC_Answer'])\n",
    "train_y = train_correct['Correct']\n",
    "\n",
    "val_qns_embed = embed(val_correct['QuestionText'])\n",
    "val_ans_embed = embed(val_correct['MC_Answer'])\n",
    "val_y = val_correct['Correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0936 - val_accuracy: 0.9862 - val_loss: 0.0345\n",
      "Epoch 2/10\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0416 - val_accuracy: 0.9862 - val_loss: 0.0343\n",
      "Epoch 3/10\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0325 - val_accuracy: 0.9862 - val_loss: 0.0322\n",
      "Epoch 4/10\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0340 - val_accuracy: 0.9862 - val_loss: 0.0336\n",
      "Epoch 5/10\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0343 - val_accuracy: 0.9862 - val_loss: 0.0331\n",
      "Epoch 6/10\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0336 - val_accuracy: 0.9862 - val_loss: 0.0351\n",
      "Epoch 7/10\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0311 - val_accuracy: 0.9862 - val_loss: 0.0324\n",
      "Epoch 8/10\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0329 - val_accuracy: 0.9862 - val_loss: 0.0330\n",
      "Epoch 9/10\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0322 - val_accuracy: 0.9862 - val_loss: 0.0349\n",
      "Epoch 10/10\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9865 - loss: 0.0338 - val_accuracy: 0.9862 - val_loss: 0.0338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e6bd84d7d0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_correct.fit(\n",
    "  [train_qns_embed, train_ans_embed],\n",
    "  train_y,\n",
    "  batch_size=32,\n",
    "  epochs=10,\n",
    "  validation_data=([val_qns_embed, val_ans_embed], val_y),\n",
    "  # callbacks=[WandbMetricsLogger()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▇█▇▆█████</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▃▁▃▃▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>██████▁███</td></tr><tr><td>epoch/val_loss</td><td>▁▄▅█▆▂▄▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.987</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.03165</td></tr><tr><td>epoch/val_accuracy</td><td>0.98619</td></tr><tr><td>epoch/val_loss</td><td>0.03322</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-universe-1</strong> at: <a href='https://wandb.ai/minimartzz/math_misunderstandings/runs/5gqspgve' target=\"_blank\">https://wandb.ai/minimartzz/math_misunderstandings/runs/5gqspgve</a><br> View project at: <a href='https://wandb.ai/minimartzz/math_misunderstandings' target=\"_blank\">https://wandb.ai/minimartzz/math_misunderstandings</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250826_213038-5gqspgve\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step\n"
     ]
    }
   ],
   "source": [
    "val_preds = model_correct.predict([val_qns_embed, val_ans_embed])\n",
    "val_preds = np.where(val_preds.flatten() > 0.5, 1, 0)\n",
    "val_results = val_split.with_columns(\n",
    "  CorrectPrediction=val_preds,\n",
    ")\n",
    "val_results = val_results.with_columns(\n",
    "  MissedCorrectPrediction=pl.col(\"CorrectPrediction\") == pl.col(\"Correct\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Category', ylabel='count'>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(val_results, x=\"Category\", hue='MissedCorrectPrediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFN for Error Classification. Combine the results of Correct prediction\n",
    "\n",
    "- 1: Error in explanation\n",
    "- 0: Neither\n",
    "- 2: Correct explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step\n"
     ]
    }
   ],
   "source": [
    "train_correct_preds = model_correct.predict([train_qns_embed, train_ans_embed])\n",
    "train_correct_preds = np.where(train_correct_preds.flatten() > 0.5, 1, 0)\n",
    "\n",
    "val_correct_preds = model_correct.predict([val_qns_embed, val_ans_embed])\n",
    "val_correct_preds = np.where(val_correct_preds.flatten() > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionText</th><th>StudentExplanation</th><th>Error</th></tr><tr><td>str</td><td>str</td><td>i8</td></tr></thead><tbody><tr><td>&quot;\\( \\frac{1}{3}+\\frac{2}{5}= \\)&quot;</td><td>&quot;i think this answer is correct…</td><td>0</td></tr><tr><td>&quot;This is part of a regular poly…</td><td>&quot;i can&#x27;t see the shape and what…</td><td>-1</td></tr><tr><td>&quot;Which number is the greatest?&quot;</td><td>&quot;this has 6 ones and 2 tenths b…</td><td>1</td></tr><tr><td>&quot;Which number is the greatest?&quot;</td><td>&quot;it has to be to the nearest 10…</td><td>0</td></tr><tr><td>&quot;What fraction of the shape is …</td><td>&quot;There is 9 triangles in the sh…</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────────────────────┬─────────────────────────────────┬───────┐\n",
       "│ QuestionText                    ┆ StudentExplanation              ┆ Error │\n",
       "│ ---                             ┆ ---                             ┆ ---   │\n",
       "│ str                             ┆ str                             ┆ i8    │\n",
       "╞═════════════════════════════════╪═════════════════════════════════╪═══════╡\n",
       "│ \\( \\frac{1}{3}+\\frac{2}{5}= \\)  ┆ i think this answer is correct… ┆ 0     │\n",
       "│ This is part of a regular poly… ┆ i can't see the shape and what… ┆ -1    │\n",
       "│ Which number is the greatest?   ┆ this has 6 ones and 2 tenths b… ┆ 1     │\n",
       "│ Which number is the greatest?   ┆ it has to be to the nearest 10… ┆ 0     │\n",
       "│ What fraction of the shape is … ┆ There is 9 triangles in the sh… ┆ 1     │\n",
       "└─────────────────────────────────┴─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate results of correct prediction with existing train errors dataset\n",
    "train_correct_p = tf.convert_to_tensor(train_correct_preds.reshape(-1, 1), dtype=tf.float32) \n",
    "val_correct_p = tf.convert_to_tensor(val_correct_preds.reshape(-1, 1), dtype=tf.float32) \n",
    "\n",
    "# Create embedding sets\n",
    "train_err_qns_embed = embed(train_error['QuestionText'])\n",
    "train_err_qns_embed = tf.concat([train_err_qns_embed, train_correct_p], axis=1)\n",
    "train_err_exp_embed = embed(train_error['StudentExplanation'])\n",
    "train_err_exp_embed = tf.concat([train_err_exp_embed, train_correct_p], axis=1)\n",
    "train_err_y = train_error['Error']\n",
    "\n",
    "val_err_qns_embed = embed(val_error['QuestionText'])\n",
    "val_err_qns_embed = tf.concat([val_err_qns_embed, val_correct_p], axis=1)\n",
    "val_err_exp_embed = embed(val_error['StudentExplanation'])\n",
    "val_err_exp_embed = tf.concat([val_err_exp_embed, val_correct_p], axis=1)\n",
    "val_err_y = val_error['Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_36          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dropout_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,260</span> │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m513\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m513\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m263,168\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m263,168\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_36          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dropout_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │     \u001b[38;5;34m10,260\u001b[0m │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m63\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">805,459</span> (3.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m805,459\u001b[0m (3.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">802,387</span> (3.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m802,387\u001b[0m (3.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> (12.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,072\u001b[0m (12.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recreate the same model architecture\n",
    "qns_input = keras.layers.Input(shape=(config['embed_dim']+1, )) # Questions\n",
    "exp_input = keras.layers.Input(shape=(config['embed_dim']+1, )) # Explanations\n",
    "\n",
    "# Questions model\n",
    "x1 = keras.layers.Dense(config['embed_dim'], activation=\"relu\")(qns_input)\n",
    "x1 = keras.layers.Dropout(config['dropout_rate'])(x1)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "x1 = keras.layers.Dense(config['ffn_dim'], activation=\"relu\")(x1)\n",
    "x1 = keras.layers.Dropout(config['dropout_rate'])(x1)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "# Explanations model\n",
    "x2 = keras.layers.Dense(config['embed_dim'], activation=\"relu\")(exp_input)\n",
    "x2 = keras.layers.Dropout(config['dropout_rate'])(x2)\n",
    "x2 = keras.layers.BatchNormalization()(x2)\n",
    "x2 = keras.layers.Dense(config['ffn_dim'], activation=\"relu\")(x2)\n",
    "x2 = keras.layers.Dropout(config['dropout_rate'])(x2)\n",
    "x2 = keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "# Combined model\n",
    "x3 = keras.layers.concatenate([x1, x2])\n",
    "x3 = keras.layers.Dropout(config['dropout_rate'])(x3)\n",
    "x3 = keras.layers.Dense(20, activation=\"relu\")(x3)\n",
    "x3 = keras.layers.Dropout(config['dropout_rate'])(x3)\n",
    "outputs = keras.layers.Dense(3, activation=\"softmax\")(x3)\n",
    "\n",
    "model_error = keras.Model(inputs=[qns_input, exp_input], outputs=outputs)\n",
    "\n",
    "model_error.compile(\n",
    "  optimizer=config['optimizer'],\n",
    "  loss=\"sparse_categorical_crossentropy\",\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "model_error.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7158 - loss: 0.6585 - val_accuracy: 0.7750 - val_loss: 0.5106\n",
      "Epoch 2/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7786 - loss: 0.5169 - val_accuracy: 0.7995 - val_loss: 0.4792\n",
      "Epoch 3/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.4669 - val_accuracy: 0.8036 - val_loss: 0.4639\n",
      "Epoch 4/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8170 - loss: 0.4396 - val_accuracy: 0.8124 - val_loss: 0.4518\n",
      "Epoch 5/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.4046 - val_accuracy: 0.8201 - val_loss: 0.4418\n",
      "Epoch 6/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.3754 - val_accuracy: 0.8142 - val_loss: 0.4559\n",
      "Epoch 7/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 0.3529 - val_accuracy: 0.8124 - val_loss: 0.4625\n",
      "Epoch 8/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8672 - loss: 0.3277 - val_accuracy: 0.8142 - val_loss: 0.4714\n",
      "Epoch 9/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.3013 - val_accuracy: 0.8162 - val_loss: 0.4890\n",
      "Epoch 10/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8815 - loss: 0.2898 - val_accuracy: 0.8199 - val_loss: 0.4979\n",
      "Epoch 11/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8861 - loss: 0.2802 - val_accuracy: 0.8139 - val_loss: 0.5161\n",
      "Epoch 12/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8997 - loss: 0.2545 - val_accuracy: 0.8193 - val_loss: 0.5312\n",
      "Epoch 13/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.2429 - val_accuracy: 0.8195 - val_loss: 0.5418\n",
      "Epoch 14/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.2256 - val_accuracy: 0.8189 - val_loss: 0.5348\n",
      "Epoch 15/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9154 - loss: 0.2168 - val_accuracy: 0.8181 - val_loss: 0.5455\n",
      "Epoch 16/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9211 - loss: 0.2003 - val_accuracy: 0.8184 - val_loss: 0.6352\n",
      "Epoch 17/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9198 - loss: 0.2066 - val_accuracy: 0.8139 - val_loss: 0.6243\n",
      "Epoch 18/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9257 - loss: 0.1902 - val_accuracy: 0.8143 - val_loss: 0.6379\n",
      "Epoch 19/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.1843 - val_accuracy: 0.8189 - val_loss: 0.6290\n",
      "Epoch 20/20\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9320 - loss: 0.1748 - val_accuracy: 0.8105 - val_loss: 0.6535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e6a47154d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_error.fit(\n",
    "  [train_err_qns_embed, train_err_exp_embed],\n",
    "  train_err_y,\n",
    "  batch_size=32,\n",
    "  epochs=20,\n",
    "  validation_data=([val_err_qns_embed, val_err_exp_embed], val_err_y),\n",
    "  # callbacks=[WandbMetricsLogger()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misconceptions model - Combination of all above features to predict a misconception. \n",
    "\n",
    "NOTE: For answers that are \"Correct\" and have no \"Errors\" they are always assigned 'NA' encode that rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Adding_across',\n",
       " 1: 'Adding_terms',\n",
       " 2: 'Additive',\n",
       " 3: 'Base_rate',\n",
       " 4: 'Certainty',\n",
       " 5: 'Definition',\n",
       " 6: 'Denominator-only_change',\n",
       " 7: 'Division',\n",
       " 8: 'Duplication',\n",
       " 9: 'Firstterm',\n",
       " 10: 'FlipChange',\n",
       " 11: 'Ignores_zeroes',\n",
       " 12: 'Incomplete',\n",
       " 13: 'Incorrect_equivalent_fraction_addition',\n",
       " 14: 'Interior',\n",
       " 15: 'Inverse_operation',\n",
       " 16: 'Inversion',\n",
       " 17: 'Irrelevant',\n",
       " 18: 'Longer_is_bigger',\n",
       " 19: 'Mult',\n",
       " 20: 'Multiplying_by_4',\n",
       " 21: 'NA',\n",
       " 22: 'Not_variable',\n",
       " 23: 'Positive',\n",
       " 24: 'Scale',\n",
       " 25: 'Shorter_is_bigger',\n",
       " 26: 'Subtraction',\n",
       " 27: 'SwapDividend',\n",
       " 28: 'Tacking',\n",
       " 29: 'Unknowable',\n",
       " 30: 'WNB',\n",
       " 31: 'Whole_numbers_larger',\n",
       " 32: 'Wrong_Fraction',\n",
       " 33: 'Wrong_Operation',\n",
       " 34: 'Wrong_fraction',\n",
       " 35: 'Wrong_term'}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = {k: v for k, v in enumerate(enc.classes_)}\n",
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step\n"
     ]
    }
   ],
   "source": [
    "# Results from model_error\n",
    "train_err_preds = model_error.predict([train_err_qns_embed, train_err_exp_embed])\n",
    "train_err_preds = np.argmax(train_err_preds, axis=1)\n",
    "\n",
    "val_err_preds = model_error.predict([val_err_qns_embed, val_err_exp_embed])\n",
    "val_err_preds = np.argmax(val_err_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both \"Correct\" and \"Error\" to misconceptions\n",
    "train_misconception = train_misconception.with_columns(\n",
    "  Correct=train_correct_preds,\n",
    "  Error=train_err_preds\n",
    ")\n",
    "\n",
    "# Split data into training and rule-based prediction\n",
    "train_actual = train_misconception.filter(\n",
    "  ( pl.col(\"Correct\") != 1 ) | ( pl.col(\"Error\") != 2 )\n",
    ")\n",
    "train_rule = train_misconception.filter(\n",
    "  ( pl.col(\"Correct\") == 1 ) & ( pl.col(\"Error\") == 2 )\n",
    ")\n",
    "\n",
    "# Create the correct and error predictions\n",
    "train_correct_p = tf.convert_to_tensor(train_actual['Correct'].to_numpy().reshape(-1, 1), dtype=tf.float32) \n",
    "train_error_p = tf.convert_to_tensor(train_actual['Error'].to_numpy().reshape(-1, 1), dtype=tf.float32) \n",
    "\n",
    "# Create the embbedings\n",
    "train_mis_qns_embed = embed(train_actual['QuestionText'])\n",
    "train_mis_qns_embed = tf.concat([train_mis_qns_embed, train_correct_p, train_error_p], axis=1)\n",
    "train_mis_exp_embed = embed(train_actual['StudentExplanation'])\n",
    "train_mis_exp_embed = tf.concat([train_mis_exp_embed, train_correct_p, train_error_p], axis=1)\n",
    "train_mis_ans_embed = embed(train_actual['MC_Answer'])\n",
    "train_mis_ans_embed = tf.concat([train_mis_ans_embed, train_correct_p, train_error_p], axis=1)\n",
    "\n",
    "train_mis_y = train_actual['Misconception']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,680</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,680</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,680</span> │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_42          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_44          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_43          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_45          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dropout_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_48          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,380</span> │ dropout_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_49          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">756</span> │ dropout_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m514\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m514\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m514\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m263,680\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m263,680\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m263,680\u001b[0m │ input_layer_16[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_42          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_44          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_46          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dropout_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dropout_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dropout_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_43          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_45          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_47          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dropout_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dropout_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dropout_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_48          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │     \u001b[38;5;34m15,380\u001b[0m │ dropout_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_49          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)        │        \u001b[38;5;34m756\u001b[0m │ dropout_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,210,376</span> (4.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,210,376\u001b[0m (4.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,205,768</span> (4.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,205,768\u001b[0m (4.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> (18.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,608\u001b[0m (18.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recreate the same model architecture\n",
    "qns_input = keras.layers.Input(shape=(config['embed_dim']+2, )) # Questions\n",
    "exp_input = keras.layers.Input(shape=(config['embed_dim']+2, )) # Explanations\n",
    "ans_input = keras.layers.Input(shape=(config['embed_dim']+2, )) # Answers\n",
    "\n",
    "# Questions model\n",
    "x1 = keras.layers.Dense(config['embed_dim'], activation=\"relu\")(qns_input)\n",
    "x1 = keras.layers.Dropout(config['dropout_rate'])(x1)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "x1 = keras.layers.Dense(config['ffn_dim'], activation=\"relu\")(x1)\n",
    "x1 = keras.layers.Dropout(config['dropout_rate'])(x1)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "# Explanations model\n",
    "x2 = keras.layers.Dense(config['embed_dim'], activation=\"relu\")(exp_input)\n",
    "x2 = keras.layers.Dropout(config['dropout_rate'])(x2)\n",
    "x2 = keras.layers.BatchNormalization()(x2)\n",
    "x2 = keras.layers.Dense(config['ffn_dim'], activation=\"relu\")(x2)\n",
    "x2 = keras.layers.Dropout(config['dropout_rate'])(x2)\n",
    "x2 = keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "# Answers model\n",
    "x3 = keras.layers.Dense(config['embed_dim'], activation=\"relu\")(ans_input)\n",
    "x3 = keras.layers.Dropout(config['dropout_rate'])(x3)\n",
    "x3 = keras.layers.BatchNormalization()(x3)\n",
    "x3 = keras.layers.Dense(config['ffn_dim'], activation=\"relu\")(x3)\n",
    "x3 = keras.layers.Dropout(config['dropout_rate'])(x3)\n",
    "x3 = keras.layers.BatchNormalization()(x3)\n",
    "\n",
    "# Combined model\n",
    "x4 = keras.layers.concatenate([x1, x2, x3])\n",
    "x4 = keras.layers.Dropout(config['dropout_rate'])(x4)\n",
    "x4 = keras.layers.Dense(20, activation=\"relu\")(x4)\n",
    "x4 = keras.layers.Dropout(config['dropout_rate'])(x4)\n",
    "outputs = keras.layers.Dense(len(mapper), activation=\"softmax\")(x4)\n",
    "\n",
    "model_misconception = keras.Model(inputs=[qns_input, exp_input, ans_input], outputs=outputs)\n",
    "\n",
    "model_misconception.compile(\n",
    "  optimizer=config['optimizer'],\n",
    "  loss=\"sparse_categorical_crossentropy\",\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "model_misconception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.8323\n",
      "Epoch 2/10\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9222 - loss: 0.2924\n",
      "Epoch 3/10\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2697\n",
      "Epoch 4/10\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9356 - loss: 0.2213\n",
      "Epoch 5/10\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.1967\n",
      "Epoch 6/10\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.1981\n",
      "Epoch 7/10\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9420 - loss: 0.1903\n",
      "Epoch 8/10\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1604\n",
      "Epoch 9/10\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9431 - loss: 0.1800\n",
      "Epoch 10/10\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.1586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e6bbd1a390>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_misconception.fit(\n",
    "  [train_mis_qns_embed, train_mis_exp_embed, train_mis_ans_embed],\n",
    "  train_mis_y,\n",
    "  batch_size=32,\n",
    "  epochs=10,\n",
    "  # validation_data=([val_err_qns_embed, val_err_exp_embed], val_err_y),\n",
    "  # callbacks=[WandbMetricsLogger()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>QuestionId</th><th>QuestionText</th><th>MC_Answer</th><th>StudentExplanation</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>36696</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;I think that 1/3 is the answer…</td></tr><tr><td>36697</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{3}{6} \\)&quot;</td><td>&quot;i think this answer is because…</td></tr><tr><td>36698</td><td>32835</td><td>&quot;Which number is the greatest?&quot;</td><td>&quot;\\( 6.2 \\)&quot;</td><td>&quot;because the 2 makes it higher …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "┌────────┬────────────┬──────────────────────┬───────────────────┬─────────────────────────────────┐\n",
       "│ row_id ┆ QuestionId ┆ QuestionText         ┆ MC_Answer         ┆ StudentExplanation              │\n",
       "│ ---    ┆ ---        ┆ ---                  ┆ ---               ┆ ---                             │\n",
       "│ i64    ┆ i64        ┆ str                  ┆ str               ┆ str                             │\n",
       "╞════════╪════════════╪══════════════════════╪═══════════════════╪═════════════════════════════════╡\n",
       "│ 36696  ┆ 31772      ┆ What fraction of the ┆ \\( \\frac{1}{3} \\) ┆ I think that 1/3 is the answer… │\n",
       "│        ┆            ┆ shape is …           ┆                   ┆                                 │\n",
       "│ 36697  ┆ 31772      ┆ What fraction of the ┆ \\( \\frac{3}{6} \\) ┆ i think this answer is because… │\n",
       "│        ┆            ┆ shape is …           ┆                   ┆                                 │\n",
       "│ 36698  ┆ 32835      ┆ Which number is the  ┆ \\( 6.2 \\)         ┆ because the 2 makes it higher … │\n",
       "│        ┆            ┆ greatest?            ┆                   ┆                                 │\n",
       "└────────┴────────────┴──────────────────────┴───────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all embeddings\n",
    "row_id = test['row_id']\n",
    "\n",
    "test_qns_embed = embed(test['QuestionText'])\n",
    "test_ans_embed = embed(test['MC_Answer'])\n",
    "test_exp_embed = embed(test['StudentExplanation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict Correct\n",
    "test_correct = model_correct.predict([test_qns_embed, test_ans_embed])\n",
    "test_correct = np.where(test_correct.flatten() > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-08-26T18:23:33.572200+08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 8.31.0\n",
      "\n",
      "Compiler    : MSC v.1938 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 183 Stepping 1, GenuineIntel\n",
      "CPU cores   : 20\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
