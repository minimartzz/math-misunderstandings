{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEFT Models\n",
    "\n",
    "Testing out PEFT with HuggingFace models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 07/10/2025   | Martin | Create  | Notebook created to test out various PEFT models with HuggingFace. Completed first cut of workflow | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Load Data](#load-data)\n",
    "* [Preprocessing](#preprocessing)\n",
    "* [Model Training](#model-training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "[ HuggingFace Source ](https://huggingface.co/docs/peft/index)\n",
    "\n",
    "PEFT (Parameter-Efficient Fine-Tuning) is a library for efficiently adapting large pretrained models to various downstream applications without fine-tuning all of a model’s parameters because it is prohibitively costly. PEFT methods only fine-tune a small number of (extra) model parameters - significantly decreasing computational and storage costs - while yielding performance comparable to a fully fine-tuned model. This makes it more accessible to train and store large language models (LLMs) on consumer hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martz/Repos/math-misunderstandings/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/raw\"\n",
    "train = pl.read_csv(f\"{path}/train.csv\")\n",
    "test = pl.read_csv(f\"{path}/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new labels\n",
    "le = LabelEncoder()\n",
    "train = train.with_columns(\n",
    "  Target = pl.col('Category') + \":\" + pl.col('Misconception'),\n",
    "  Correct = pl.col(\"Category\").str.split(\"_\").list.last() == \"Correct\"\n",
    ")\n",
    "train = train.with_columns(\n",
    "  labels = pl.col(\"Target\").map_batches(le.fit_transform)\n",
    ")\n",
    "\n",
    "# Get known answers\n",
    "temp = train.filter(\n",
    "  pl.col('Correct')\n",
    ")\n",
    "temp = temp.group_by(['QuestionId', 'MC_Answer']).len().sort('len', descending=True)\n",
    "temp = temp.unique(subset=['QuestionId'])\n",
    "temp = temp.drop('len')\n",
    "temp = temp.with_columns(\n",
    "  Correct=1\n",
    ")\n",
    "\n",
    "# Evaluate correctness of test set answer\n",
    "test = test.join(\n",
    "  temp,\n",
    "  how='left',\n",
    "  on=['QuestionId', 'MC_Answer']\n",
    ")\n",
    "test = test.fill_null(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(df):\n",
    "  df = df.with_columns(\n",
    "    pl.when(pl.col(\"Correct\") == 1)\n",
    "      .then(pl.lit(\"This answer is correct.\"))\n",
    "      .otherwise(pl.lit(\"This answer is wrong.\"))\n",
    "      .alias(\"Correctness\")\n",
    "  )\n",
    "\n",
    "  return df.with_columns(\n",
    "    pl.format(\n",
    "      \"Question:\\n{}\\nAnswer:\\n{}\\nCorrect:\\n{}\\nExplanation:\\n{}\",\n",
    "      df['QuestionText'],\n",
    "      df['MC_Answer'],\n",
    "      df['Correctness'],\n",
    "      df['StudentExplanation']\n",
    "    ).alias(\"text\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = format_input(train)\n",
    "test = format_input(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>QuestionId</th><th>QuestionText</th><th>MC_Answer</th><th>StudentExplanation</th><th>Category</th><th>Misconception</th><th>Target</th><th>Correct</th><th>labels</th><th>Correctness</th><th>text</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;0ne third is equal to tree nin…</td><td>&quot;True_Correct&quot;</td><td>&quot;NA&quot;</td><td>&quot;True_Correct:NA&quot;</td><td>true</td><td>37</td><td>&quot;This answer is correct.&quot;</td><td>&quot;Question:\n",
       "What fraction of the…</td></tr><tr><td>1</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 / 3 because 6 over 9 is 2 th…</td><td>&quot;True_Correct&quot;</td><td>&quot;NA&quot;</td><td>&quot;True_Correct:NA&quot;</td><td>true</td><td>37</td><td>&quot;This answer is correct.&quot;</td><td>&quot;Question:\n",
       "What fraction of the…</td></tr><tr><td>2</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 3rd is half of 3 6th, so it …</td><td>&quot;True_Neither&quot;</td><td>&quot;NA&quot;</td><td>&quot;True_Neither:NA&quot;</td><td>false</td><td>64</td><td>&quot;This answer is wrong.&quot;</td><td>&quot;Question:\n",
       "What fraction of the…</td></tr><tr><td>3</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 goes into everything and 3 g…</td><td>&quot;True_Neither&quot;</td><td>&quot;NA&quot;</td><td>&quot;True_Neither:NA&quot;</td><td>false</td><td>64</td><td>&quot;This answer is wrong.&quot;</td><td>&quot;Question:\n",
       "What fraction of the…</td></tr><tr><td>4</td><td>31772</td><td>&quot;What fraction of the shape is …</td><td>&quot;\\( \\frac{1}{3} \\)&quot;</td><td>&quot;1 out of every 3 isn&#x27;t coloure…</td><td>&quot;True_Correct&quot;</td><td>&quot;NA&quot;</td><td>&quot;True_Correct:NA&quot;</td><td>true</td><td>37</td><td>&quot;This answer is correct.&quot;</td><td>&quot;Question:\n",
       "What fraction of the…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 12)\n",
       "┌────────┬────────────┬─────────────┬─────────────┬───┬─────────┬────────┬────────────┬────────────┐\n",
       "│ row_id ┆ QuestionId ┆ QuestionTex ┆ MC_Answer   ┆ … ┆ Correct ┆ labels ┆ Correctnes ┆ text       │\n",
       "│ ---    ┆ ---        ┆ t           ┆ ---         ┆   ┆ ---     ┆ ---    ┆ s          ┆ ---        │\n",
       "│ i64    ┆ i64        ┆ ---         ┆ str         ┆   ┆ bool    ┆ i64    ┆ ---        ┆ str        │\n",
       "│        ┆            ┆ str         ┆             ┆   ┆         ┆        ┆ str        ┆            │\n",
       "╞════════╪════════════╪═════════════╪═════════════╪═══╪═════════╪════════╪════════════╪════════════╡\n",
       "│ 0      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ true    ┆ 37     ┆ This       ┆ Question:  │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆         ┆        ┆ answer is  ┆ What       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆         ┆        ┆ correct.   ┆ fraction   │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆         ┆        ┆            ┆ of the…    │\n",
       "│ 1      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ true    ┆ 37     ┆ This       ┆ Question:  │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆         ┆        ┆ answer is  ┆ What       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆         ┆        ┆ correct.   ┆ fraction   │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆         ┆        ┆            ┆ of the…    │\n",
       "│ 2      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ false   ┆ 64     ┆ This       ┆ Question:  │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆         ┆        ┆ answer is  ┆ What       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆         ┆        ┆ wrong.     ┆ fraction   │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆         ┆        ┆            ┆ of the…    │\n",
       "│ 3      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ false   ┆ 64     ┆ This       ┆ Question:  │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆         ┆        ┆ answer is  ┆ What       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆         ┆        ┆ wrong.     ┆ fraction   │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆         ┆        ┆            ┆ of the…    │\n",
       "│ 4      ┆ 31772      ┆ What        ┆ \\(          ┆ … ┆ true    ┆ 37     ┆ This       ┆ Question:  │\n",
       "│        ┆            ┆ fraction of ┆ \\frac{1}{3} ┆   ┆         ┆        ┆ answer is  ┆ What       │\n",
       "│        ┆            ┆ the shape   ┆ \\)          ┆   ┆         ┆        ┆ correct.   ┆ fraction   │\n",
       "│        ┆            ┆ is …        ┆             ┆   ┆         ┆        ┆            ┆ of the…    │\n",
       "└────────┴────────────┴─────────────┴─────────────┴───┴─────────┴────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train.select([\"text\", \"labels\"])\n",
    "train_ds = Dataset.from_polars(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = len(train['labels'].unique())\n",
    "MODEL_PATH = \"deepseek-ai/deepseek-math-7b-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokeniser\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files:   0%|          | 0/2 [04:44<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "  MODEL_PATH,\n",
    "  num_labels=NUM_LABELS,\n",
    "  dtype=torch.bfloat16,\n",
    "  device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜end▁of▁sentence｜>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "  task_type=TaskType.SEQ_CLS,\n",
    "  r=16,\n",
    "  lora_alpha=32, # A common practice is to double the r value\n",
    "  target_modules=[\"query\", \"value\"],\n",
    "  lora_dropout=0.1,\n",
    "  bias=\"none\",\n",
    "  modules_to_save=[\"classifier\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=\"models/deepseek_base_misunderstanding\",\n",
    "  learning_rate=5e-3,\n",
    "  per_device_train_batch_size=32,\n",
    "  per_device_eval_batch_size=32,\n",
    "  gradient_accumulation_steps=4,\n",
    "  num_train_epochs=10,\n",
    "  weight_decay=0.01,\n",
    "  eval_strategy=\"epoch\",\n",
    "  save_strategy=\"epoch\",\n",
    "  load_best_model_at_end=True,\n",
    "  fp16=True,\n",
    "  label_names=[\"labels\"]\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  train_dataset=train_ds,\n",
    "  processing_class=tokenizer,\n",
    "  data_collator=DataCollatorWithPadding(tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_tokenized)\n",
    "logits = predictions.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-10-07T16:08:48.982864+08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 9.3.0\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.30)\n",
      "OS          : Darwin\n",
      "Release     : 24.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 10\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
